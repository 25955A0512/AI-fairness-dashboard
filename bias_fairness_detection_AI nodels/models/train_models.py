# models/train_models.py

import pandas as pd
import joblib
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from fairlearn.reductions import ExponentiatedGradient, DemographicParity

# ðŸ“¥ Load cleaned dataset
df = pd.read_csv("data/adult_cleaned.csv")

# ðŸŽ¯ Define features, labels, and sensitive attribute
X = df.drop(columns=["income", "sex_original"])
y = df["income"]
sensitive_feature = df["sex_original"]

# ðŸ“Š Scale features for better convergence
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# âœ… Train original logistic regression model
original_model = LogisticRegression(max_iter=2000)
original_model.fit(X_scaled, y)
joblib.dump(original_model, "models/logistic_model.pkl")
print("âœ… Original model saved.")

# âœ… Train fairness-mitigated model using ExponentiatedGradient
mitigator = ExponentiatedGradient(
    estimator=LogisticRegression(max_iter=2000),
    constraints=DemographicParity()
)
mitigator.fit(X_scaled, y, sensitive_features=sensitive_feature)
joblib.dump(mitigator, "models/mitigated_model.pkl")
print("âœ… Mitigated model saved.")

# ðŸ’¾ Save the scaler for consistent preprocessing during inference
joblib.dump(scaler, "models/scaler.pkl")
print("âœ… Scaler saved.")
